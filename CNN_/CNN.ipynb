{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0PYzOB9ORZk",
        "colab_type": "code",
        "outputId": "feee6560-eafa-4235-c7fc-186a30a69df8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "import torch\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "import numpy as np\n",
        "import copy\n",
        "import random\n",
        "from collections import Counter\n",
        "import nltk\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "nltk.download(\"popular\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ucphi2TWu89",
        "colab_type": "code",
        "outputId": "cbc9f152-373e-4399-f90d-573eac04eccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCRYC0t2XSS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train data & Test data setting\n",
        "# Load data set\n",
        "positive_data = open('/content/gdrive/My Drive/rt-polaritydata/rt-polarity.pos.txt', mode='rb').read()\n",
        "negative_data = open('/content/gdrive/My Drive/rt-polaritydata/rt-polarity.neg.txt', mode='rb').read()\n",
        "\n",
        "# Make entire words embedding vectors\n",
        "# 1. convert bytes to utf-8\n",
        "decoded_positive_data = positive_data.decode(\"utf-8\", errors=\"replace\")\n",
        "decoded_negative_data = negative_data.decode(\"utf-8\", errors=\"replace\")\n",
        "\n",
        "# 2. split by sentences with nltk\n",
        "pre_positive_sentences =  list(set([\n",
        "                      sentence for sentence in nltk.sent_tokenize(decoded_positive_data)\n",
        "                      ]))\n",
        "\n",
        "pre_negative_sentences = list(set([\n",
        "                      sentence for sentence in nltk.sent_tokenize(decoded_negative_data)\n",
        "                      ]))\n",
        "\n",
        "positive_sentences = [item for item in pre_positive_sentences if item not in pre_negative_sentences]\n",
        "negative_sentences = [item for item in pre_negative_sentences if item not in pre_positive_sentences]\n",
        "\n",
        "# 2-1. give a class label to each sentence group\n",
        "positive_classes = [1 for i in range(len(positive_sentences))]\n",
        "negative_classes = [0 for i in range(len(negative_sentences))]\n",
        "\n",
        "# combine sentences and classses\n",
        "all_sentences = positive_sentences + negative_sentences\n",
        "all_classes = positive_classes + negative_classes\n",
        "\n",
        "# 3. give indices/class label to every sentences\n",
        "# sentence index to sentence & sentence to sentence index\n",
        "si2s = {}\n",
        "s2si = {}\n",
        "for index, sentence in enumerate(all_sentences):\n",
        "    si2s[index] = sentence\n",
        "    s2si[sentence] = index\n",
        "\n",
        "# sentence index to class label\n",
        "si2c = {}\n",
        "for index, class_label in enumerate(all_classes):\n",
        "    si2c[index] = class_label\n",
        "\n",
        "# 4.get all words list\n",
        "# 4-1. get max numbers of words in each one sentence\n",
        "word_list = []\n",
        "# sentence_length = []\n",
        "stopwords = [',', '.', '(', ')', '-', '--', '[', ']', '`', '\\'', '``', '\\\"' ]\n",
        "for sentence in all_sentences:\n",
        "    sentence_words = [\n",
        "                      word for word in nltk.word_tokenize(sentence)\n",
        "                      if word not in stopwords\n",
        "                      ]\n",
        "    word_list += sentence_words\n",
        "    # sentence_length.append(len(sentence_words))\n",
        "\n",
        "word_list += ['<PAD>']\n",
        "\n",
        "# number of all sentences/words\n",
        "num_sentences = len(all_sentences)\n",
        "num_words = len(word_list)\n",
        "# max_sentence = max(sentence_length)\n",
        "\n",
        "# 5. give indices to every words\n",
        "wi2w = {}\n",
        "w2wi = {}\n",
        "for index, word in enumerate(word_list):\n",
        "    wi2w[index] = word\n",
        "    w2wi[word] = index\n",
        "\n",
        "# 6. give word indices to each sentence index\n",
        "si2wi = {}\n",
        "wi2si = {}\n",
        "for sentence in all_sentences:\n",
        "    sent_index = s2si[sentence]\n",
        "    sentence_words = [\n",
        "                      word for word in nltk.word_tokenize(sentence)\n",
        "                      if word not in stopwords\n",
        "                      ]\n",
        "    sentence_word_indices = [w2wi[word] for word in sentence_words]\n",
        "    si2wi[sent_index] = sentence_word_indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa9GyMRphPJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split Training set and Test set with 9:1\n",
        "# 정확한 비율은 아니나 편의를 위해 10000:나머지 로 나눈다.\n",
        "sample_list = [i for i in range(num_sentences)]\n",
        "testing_set = random.sample(sample_list, (num_sentences-10000))\n",
        "training_set = [index for index in sample_list if index not in testing_set]\n",
        "\n",
        "# shuffle data set\n",
        "random.shuffle(training_set)\n",
        "random.shuffle(testing_set)\n",
        "\n",
        "num_training_set = len(training_set)\n",
        "num_testing_set = len(testing_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pcHlilCt7R_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args = {\n",
        "    'vocab_num': num_words,\n",
        "    'dimension': 300,\n",
        "    'class_num': 2,\n",
        "    'filter_num': 100,\n",
        "    'filter_size': [3,4,5],\n",
        "    'dropout': 0.5,\n",
        "    'epoch': 10,\n",
        "    'learning_rate': 0.001,\n",
        "    'batch_size': 50,\n",
        "    'hidden_layer': 100,\n",
        "    'padding_index': w2wi['<PAD>'],\n",
        "    'mode': 'rand'\n",
        "}\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-di7Ifkx17j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Google News vector 사용위한 function\n",
        "def get_vector():\n",
        "    vectors = []\n",
        "    word2vec = KeyedVectors.load_word2vec_format(\n",
        "                '/content/gdrive/My Drive/rt-polaritydata/GoogleNews-vectors-negative300.bin',\n",
        "                binary=True)\n",
        "    for i in range(num_words):\n",
        "        word = wi2w[i]\n",
        "        if word in word2vec.vocab:\n",
        "            vectors.append(torch.from_numpy(word2vec[word]))\n",
        "        else:\n",
        "            vectors.append(torch.FloatTensor(args['dimension']).uniform_(-0.01, 0.01))\n",
        "\n",
        "    return torch.stack(vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeKrj_gNfyvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CNN model\n",
        "class CNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, args):\n",
        "        super(CNN, self).__init__()\n",
        "        self.args = args\n",
        "        \n",
        "        # mode = 'rand'일때\n",
        "        # 전체 vocab의 수(words의 수)\n",
        "        vocab_num = args['vocab_num']\n",
        "        # embedding vector의 feature dimension 수\n",
        "        dimension = args['dimension']\n",
        "        # class number\n",
        "        class_num = args['class_num']\n",
        "        # in channels\n",
        "        in_channel = 1\n",
        "        # hidden layer size\n",
        "        hidden_layer = args['hidden_layer']\n",
        "        # filter num\n",
        "        filter_num = args['filter_num']\n",
        "        # filter size default = [3,4,5]\n",
        "        filter_size = args['filter_size']\n",
        "        # dropout rate\n",
        "        dropout = args['dropout']\n",
        "        # padding index\n",
        "        self.padding_index = args['padding_index']\n",
        "\n",
        "        if args['mode'] == 'rand':\n",
        "            self.embedding = nn.Embedding(vocab_num, dimension, padding_idx=self.padding_index)\n",
        "\n",
        "        # rand가 아니면 embedding vector는 pre-trained 구글 벡터를 가져오기\n",
        "        google_vectors = get_vector()\n",
        "        if args['mode'] != 'rand':\n",
        "            self.embedding = nn.Embedding.from_pretrained(google_vectors, freeze=False)\n",
        "            \n",
        "        # static일 경우는 vector update없이\n",
        "        if args['mode'] == 'static':\n",
        "            self.embedding.freeze = True\n",
        "\n",
        "        # multi-channel은 하나의 embedding vector를 더 사용\n",
        "        # 둘 다 pre-trained를 사용하지만, 하나만 학습되고 하나는 static\n",
        "        # embedding2가 static하도록 설정\n",
        "        if args['mode'] == 'multichannel':\n",
        "            self.embedding2 = nn.Embedding.from_pretrained(google_vectors)\n",
        "            in_channel = 2\n",
        "\n",
        "        self.convs_1ist = nn.ModuleList(\n",
        "            [nn.Conv2d(in_channel, filter_num, (size, dimension)) for size in filter_size]\n",
        "            )\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(len(filter_size)*filter_num, hidden_layer),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_layer, class_num),\n",
        "\n",
        "        )\n",
        "        # self.dropout = nn.Dropout(args['dropout'])\n",
        "        # self.fully_connected = nn.Linear(len(filter_size)*filter_num, class_num)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # multichannel의 경우 concatenate하여 두 vector를 쌓아올려준다\n",
        "        if args['mode'] == 'multichannel':\n",
        "            non_static_embedding = self.embedding(x)\n",
        "            static_embedding = self.embedding2(x)\n",
        "            x = torch.stack([non_static_embedding, static_embedding], dim=1)\n",
        "        else :\n",
        "            x = self.embedding(x)\n",
        "            x = x.unsqueeze(1)    \n",
        "        \n",
        "\n",
        "        x_relu = [F.relu(conv(x)).squeeze(3) for conv in self.convs_1ist]\n",
        "        x_pool = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x_relu]\n",
        "\n",
        "        x_concat = torch.cat(x_pool, 1)\n",
        "        output = self.linear(x_concat)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjJpJnt2RVBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(args):\n",
        "    epochs = args['epoch']\n",
        "    learning_rate = args['learning_rate']\n",
        "    batch_size = args['batch_size']\n",
        "\n",
        "    model = CNN(args)\n",
        "    optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate, weight_decay=1e-4)\n",
        "    criterion = nn.CrossEntropyLoss(reduction='sum')\n",
        "\n",
        "    loss_list = []\n",
        "\n",
        "    # Training session\n",
        "    for epoch in range(0, epochs):\n",
        "        model.train()\n",
        "\n",
        "        for start_index, end_index in zip(\n",
        "            range(0, num_training_set, batch_size),\n",
        "            range(batch_size, num_training_set+1, batch_size)):\n",
        "            train_list = []\n",
        "            class_list = []\n",
        "            pad = w2wi['<PAD>']\n",
        "            max_len = 50\n",
        "            train_loss = 0\n",
        "\n",
        "            for sentence_index in training_set[start_index: end_index]:\n",
        "                length = len(si2wi[sentence_index])\n",
        "                if length < max_len:\n",
        "                    si2wi[sentence_index] += [pad] * (max_len - length)\n",
        "                elif length > max_len:\n",
        "                    si2wi[sentence_index] = si2wi[sentence_index][:max_len]\n",
        "\n",
        "                train_list.append(\n",
        "                    torch.unsqueeze(Variable(torch.LongTensor(si2wi[sentence_index])), 0)\n",
        "                    )\n",
        "                class_list.append(si2c[sentence_index])\n",
        "\n",
        "            scores = model(torch.squeeze(torch.stack(train_list, 1)))\n",
        "            var_class = Variable(torch.LongTensor(class_list))\n",
        "\n",
        "            predict = F.softmax(scores, dim=1).argmax(dim=1)# \n",
        "\n",
        "            accuracy = torch.sum(predict == var_class).item() / batch_size\n",
        "\n",
        "            loss = criterion(scores, var_class)\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        print(f'Epoch: {epoch}\\nloss: {train_loss/batch_size}, accuracy: {accuracy}')\n",
        "\n",
        "        loss_list.append(train_loss/batch_size)\n",
        "\n",
        "    # Test session\n",
        "    model.eval()\n",
        "    pad = w2wi['<PAD>']\n",
        "    max_len = 50\n",
        "    test_list = []\n",
        "    index_list = []\n",
        "    for sentence_index in testing_set:\n",
        "        length = len(si2wi[sentence_index])\n",
        "        if length < max_len:\n",
        "            si2wi[sentence_index] += [pad] * (max_len - length)\n",
        "        elif length > max_len:\n",
        "            si2wi[sentence_index] = si2wi[sentence_index][:max_len]\n",
        "\n",
        "        test_list.append(\n",
        "            torch.unsqueeze(Variable(torch.LongTensor(si2wi[sentence_index])), 0)\n",
        "            )\n",
        "        index_list.append(si2c[sentence_index])\n",
        "\n",
        "    test_scores = model(torch.squeeze(torch.stack(test_list, 1)))\n",
        "    test_class = Variable(torch.LongTensor(index_list))\n",
        "\n",
        "    test_predict = F.softmax(test_scores, dim=1).argmax(dim = 1)\n",
        "    test_accuracy = torch.sum(test_predict == test_class).item() / num_testing_set\n",
        "    loss = criterion(test_scores, test_class)\n",
        "\n",
        "    print(f'Test Result\\nTest Loss: {loss.item()/num_testing_set}, Test Accuracy: {test_accuracy}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b070YkbVc8ua",
        "colab_type": "code",
        "outputId": "914f6888-9a96-4d89-9789-a678933c7a40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "train(args)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "loss: 0.5757014083862305, accuracy: 0.7\n",
            "Epoch: 1\n",
            "loss: 0.3170578765869141, accuracy: 0.84\n",
            "Epoch: 2\n",
            "loss: 0.03739868640899658, accuracy: 0.98\n",
            "Epoch: 3\n",
            "loss: 0.02394737720489502, accuracy: 1.0\n",
            "Epoch: 4\n",
            "loss: 0.004188187420368195, accuracy: 1.0\n",
            "Epoch: 5\n",
            "loss: 0.002179316133260727, accuracy: 1.0\n",
            "Epoch: 6\n",
            "loss: 0.0029251980781555176, accuracy: 1.0\n",
            "Epoch: 7\n",
            "loss: 7.993518374860287e-05, accuracy: 1.0\n",
            "Epoch: 8\n",
            "loss: 0.0004614561423659325, accuracy: 1.0\n",
            "Epoch: 9\n",
            "loss: 0.0154403817653656, accuracy: 1.0\n",
            "Test Result\n",
            "Test Loss: 2.0243234536082473, Test Accuracy: 0.7439862542955327\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpSlV_OUeqZL",
        "colab_type": "code",
        "outputId": "e940a764-b94b-4299-f46f-c9b21c3b1464",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "args['mode'] = 'static'\n",
        "train(args)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "loss: 0.5616396713256836, accuracy: 0.7\n",
            "Epoch: 1\n",
            "loss: 0.3522276306152344, accuracy: 0.86\n",
            "Epoch: 2\n",
            "loss: 0.07755455493927002, accuracy: 0.98\n",
            "Epoch: 3\n",
            "loss: 0.008515973687171935, accuracy: 1.0\n",
            "Epoch: 4\n",
            "loss: 0.002447342425584793, accuracy: 1.0\n",
            "Epoch: 5\n",
            "loss: 0.0019356055557727813, accuracy: 1.0\n",
            "Epoch: 6\n",
            "loss: 0.003267463743686676, accuracy: 1.0\n",
            "Epoch: 7\n",
            "loss: 0.09863566398620606, accuracy: 0.96\n",
            "Epoch: 8\n",
            "loss: 0.07304125308990478, accuracy: 0.98\n",
            "Epoch: 9\n",
            "loss: 0.0001586354523897171, accuracy: 1.0\n",
            "Test Result\n",
            "Test Loss: 2.2795057788337627, Test Accuracy: 0.7173539518900344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkpwS2W_dQGA",
        "colab_type": "code",
        "outputId": "ef96de21-76a1-4c18-a282-e87e81b81d53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "args['mode'] = 'non-static'\n",
        "train(args)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "loss: 0.49863475799560547, accuracy: 0.7\n",
            "Epoch: 1\n",
            "loss: 0.3798704147338867, accuracy: 0.82\n",
            "Epoch: 2\n",
            "loss: 0.04664958953857422, accuracy: 0.98\n",
            "Epoch: 3\n",
            "loss: 0.010416384935379028, accuracy: 1.0\n",
            "Epoch: 4\n",
            "loss: 0.008935202956199645, accuracy: 1.0\n",
            "Epoch: 5\n",
            "loss: 0.0006413940340280533, accuracy: 1.0\n",
            "Epoch: 6\n",
            "loss: 0.004944433271884918, accuracy: 1.0\n",
            "Epoch: 7\n",
            "loss: 0.002360856980085373, accuracy: 1.0\n",
            "Epoch: 8\n",
            "loss: 0.00354162335395813, accuracy: 1.0\n",
            "Epoch: 9\n",
            "loss: 0.07173749446868896, accuracy: 0.96\n",
            "Test Result\n",
            "Test Loss: 2.0952786055627146, Test Accuracy: 0.7044673539518901\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i0fiR_VX3Ov",
        "colab_type": "code",
        "outputId": "db1fbd85-ee16-47a6-a28b-0af8177abc84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "args['mode'] = 'multichannel'\n",
        "train(args)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "loss: 0.524925308227539, accuracy: 0.7\n",
            "Epoch: 1\n",
            "loss: 0.4020498275756836, accuracy: 0.84\n",
            "Epoch: 2\n",
            "loss: 0.08921781539916993, accuracy: 0.98\n",
            "Epoch: 3\n",
            "loss: 0.006928830742835999, accuracy: 1.0\n",
            "Epoch: 4\n",
            "loss: 0.007732195258140564, accuracy: 1.0\n",
            "Epoch: 5\n",
            "loss: 0.001774752289056778, accuracy: 1.0\n",
            "Epoch: 6\n",
            "loss: 0.013980120420455933, accuracy: 1.0\n",
            "Epoch: 7\n",
            "loss: 0.00020490977913141252, accuracy: 1.0\n",
            "Epoch: 8\n",
            "loss: 0.019507091045379638, accuracy: 0.98\n",
            "Epoch: 9\n",
            "loss: 0.02264051914215088, accuracy: 0.98\n",
            "Test Result\n",
            "Test Loss: 2.0032958984375, Test Accuracy: 0.7289518900343642\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-5q1mlYYDJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}